{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56906be3",
   "metadata": {},
   "source": [
    "## Pumpkinmeter: # A Movie Recommendation Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c3d61",
   "metadata": {},
   "source": [
    "### source: https://www.codementor.io/@jadianes/building-a-recommender-with-apache-spark-python-example-app-part1-du1083qbw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e1ed9",
   "metadata": {},
   "source": [
    "#### Create a SparkContext configured for local mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83895a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99605881",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60ac08",
   "metadata": {},
   "source": [
    "#### Download location(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b17551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets_path = os.path.join('..', 'datasets')\n",
    "\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a5c8a",
   "metadata": {},
   "source": [
    "#### Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9180176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "small_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)\n",
    "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81909043",
   "metadata": {},
   "source": [
    "#### Extracting file(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ddd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "    \n",
    "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efadd93",
   "metadata": {},
   "source": [
    "## Using small dataset to find the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426b1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d828db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df12835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a478cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)'),\n",
       " ('2', 'Jumanji (1995)'),\n",
       " ('3', 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
    "\n",
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
    "    \n",
    "small_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b08ed8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb78d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.908078105265682\n",
      "For rank 8 the RMSE is 0.916462973348527\n",
      "For rank 12 the RMSE is 0.917665030756129\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print ('For rank {} the RMSE is {}'.format(rank, error) )\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print ('The best model was trained with rank {}'.format(best_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "848aa713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is  0.9113780946334407\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print('For testing data the RMSE is ',error )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80babb9e",
   "metadata": {},
   "source": [
    "### Load complete ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acbdb3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33832162 recommendations in the complete dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1, 4.0), (1, 110, 4.0), (1, 158, 4.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
    "# Parse\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "\n",
    "print ('There are {} recommendations in the complete dataset'.format(complete_ratings_data.count()))\n",
    "complete_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf388be",
   "metadata": {},
   "source": [
    "### Training the ratings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa69e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88d71ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is  0.8257054095972955\n"
     ]
    }
   ],
   "source": [
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is ', (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9304c",
   "metadata": {},
   "source": [
    "### Load movies name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb9ded54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86537 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    \n",
    "print (\"There are {} movies in the complete dataset\".format(complete_movies_titles.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75d299eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f21bd2",
   "metadata": {},
   "source": [
    "### User 1 and their recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d26bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings:  [(0, 147542, 4), (0, 207313, 1.5), (0, 220104, 1.5), (0, 78039, 1.5), (0, 45720, 4), (0, 109487, 4.5), (0, 134130, 4.5), (0, 116797, 4.5), (0, 106002, 3.5), (0, 192283, 4)]\n",
      "New model trained in 213.528 seconds\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "    (0,147542,4), # Terminal (1996)\n",
    "    (0,207313,1.5), # Knives Out (2019)\n",
    "    (0,220104,1.5), # Drive (2019)\n",
    "    (0,78039,1.5), # Blue Valentine (2010)\n",
    "    (0,45720,4), # Devil Wears Prada, The (2006)\n",
    "    (0,109487,4.5), # Interstellar (2014)\n",
    "    (0,134130,4.5), # The Martian (2015)\n",
    "    (0,116797,4.5), # The Imitation Game (2014)\n",
    "    (0,106002,3.5), # Ender's Game (2013)\n",
    "    (0,192283,4), # Crazy Rich Asians (2018)\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: ', new_user_ratings_RDD.take(10))\n",
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n",
    "\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print (\"New model trained in {} seconds\".format(round(tt,3)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63797331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 15 recommended movies (with more than 25 reviews):\n",
      "('Mower Minions (2016)', 4.4931411311453235, 42)\n",
      "('Flywheel (2003)', 4.428797085077275, 31)\n",
      "('Fireproof (2008)', 4.390744448603254, 264)\n",
      "('One Piece Film: GOLD (2016)', 4.369903352972412, 42)\n",
      "('The Bible (2013)', 4.369476398401672, 31)\n",
      "('Scusa ma ti chiamo amore (2008)', 4.328424174781761, 39)\n",
      "('Minions: Orientation Day (2010)', 4.325486897298378, 37)\n",
      "('One Piece: Stampede (2019)', 4.274530072848607, 34)\n",
      "('Detective Conan: The Last Wizard of the Century (1999)', 4.264817454298781, 34)\n",
      "('What a Beautiful Day (2011)', 4.2519894353765135, 31)\n",
      "('Facing the Giants (2006)', 4.232164443918677, 204)\n",
      "('Pollyanna (2003)', 4.225019597916236, 33)\n",
      "('Naruto Shippuden the Movie: Blood Prison (2011)', 4.22116338807817, 38)\n",
      "('Minions: Banana (2010)', 4.2173592576965735, 40)\n",
      "('Shaadi Mein Zaroor Aana (2017)', 4.212495911939958, 26)\n",
      "\n",
      "TOP 15 recommended movies (with more than 100 reviews):\n",
      "('Fireproof (2008)', 4.390744448603254, 264)\n",
      "('Facing the Giants (2006)', 4.232164443918677, 204)\n",
      "('Courageous (2011)', 4.2023301615978115, 200)\n",
      "('Avengers: Infinity War - Part II (2019)', 4.197911537965097, 12845)\n",
      "('\"Ultimate Gift', 4.1687549218220035, 316)\n",
      "('War Room (2015)', 4.165887898819111, 108)\n",
      "('Avengers: Infinity War - Part I (2018)', 4.136460675181281, 16164)\n",
      "('Harry Potter and the Deathly Hallows: Part 2 (2011)', 4.096396917785892, 20837)\n",
      "('\"Avengers', 4.062085288448504, 27495)\n",
      "('Harry Potter and the Deathly Hallows: Part 1 (2010)', 4.061989039886199, 21781)\n",
      "('Gifted Hands: The Ben Carson Story (2009)', 4.056997781405625, 153)\n",
      "('Harry Potter and the Half-Blood Prince (2009)', 4.050700826355267, 21849)\n",
      "('Harry Potter and the Order of the Phoenix (2007)', 4.03624641206706, 21900)\n",
      "('Miracles from Heaven (2016)', 4.031550934628362, 107)\n",
      "('Kung Fu Panda: Secrets of the Masters (2011)', 4.028337015274499, 134)\n"
     ]
    }
   ],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "\n",
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print('TOP 15 recommended movies (with more than 25 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))\n",
    "\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=100).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print('\\nTOP 15 recommended movies (with more than 100 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c68e2",
   "metadata": {},
   "source": [
    "### User 2 and their recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a61a8caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings:  [(0, 103228, 4), (0, 115149, 4.5), (0, 7454, 3.5), (0, 84152, 4.5), (0, 122916, 4.5), (0, 201773, 4), (0, 274053, 5), (0, 177765, 5), (0, 72378, 4), (0, 59315, 4.5)]\n",
      "New model trained in 170.886 seconds\n",
      "TOP 15 recommended movies (with more than 25 reviews):\n",
      "('Band of Brothers (2001)', 5.068602905238924, 2835)\n",
      "('Planet Earth II (2016)', 5.020846141996181, 2041)\n",
      "('Planet Earth (2006)', 5.015570009897525, 3015)\n",
      "('\"Shawshank Redemption', 5.004293973400436, 122296)\n",
      "('Cosmos: A Spacetime Odissey', 4.9976465599722655, 599)\n",
      "('His Last Vow', 4.941830866446576, 41)\n",
      "('Three Men and a Leg (1997)', 4.934922527691409, 29)\n",
      "('Firefly (2002)', 4.894696099539658, 895)\n",
      "('Attack On Titan (2013)', 4.8937120159325325, 263)\n",
      "('Violet Evergarden: The Movie (2020)', 4.88186981898267, 25)\n",
      "('Spider-Man: Across the Spider-Verse (2023)', 4.88018285501334, 528)\n",
      "('Twelve Angry Men (1954)', 4.879578967336652, 332)\n",
      "('Blue Planet II (2017)', 4.879547543127085, 1267)\n",
      "('Hornblower: The Even Chance (1998)', 4.876003085797272, 33)\n",
      "('Indictment: The McMartin Trial (1995)', 4.874707446784466, 29)\n",
      "\n",
      "TOP 15 recommended movies (with more than 100 reviews):\n",
      "('Band of Brothers (2001)', 5.068602905238924, 2835)\n",
      "('Planet Earth II (2016)', 5.020846141996181, 2041)\n",
      "('Planet Earth (2006)', 5.015570009897525, 3015)\n",
      "('\"Shawshank Redemption', 5.004293973400436, 122296)\n",
      "('Cosmos: A Spacetime Odissey', 4.9976465599722655, 599)\n",
      "('Firefly (2002)', 4.894696099539658, 895)\n",
      "('Attack On Titan (2013)', 4.8937120159325325, 263)\n",
      "('Spider-Man: Across the Spider-Verse (2023)', 4.88018285501334, 528)\n",
      "('Twelve Angry Men (1954)', 4.879578967336652, 332)\n",
      "('Blue Planet II (2017)', 4.879547543127085, 1267)\n",
      "('Death Note: Desu nôto (2006–2007)', 4.866705942701085, 509)\n",
      "('The Rescue (2021)', 4.856851050392313, 141)\n",
      "('Human Planet (2011)', 4.831120341250505, 498)\n",
      "('Cosmos', 4.828845388084188, 625)\n",
      "('The Blue Planet (2001)', 4.820387703031483, 1080)\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "    (0,103228,4), # Pacific Rim (2013)\n",
    "    (0,115149,4.5), # John Wick (2014)\n",
    "    (0,7454,3.5), # Van Helsing (2004)\n",
    "    (0,84152,4.5), # Limitless (2011)\n",
    "    (0,122916,4.5), # Thor: Ragnarok (2017)\n",
    "    (0,201773,4), # Spider-Man: Far from Home (2019)\n",
    "    (0,274053,5), # Top Gun: Maverick (2022)\n",
    "    (0,177765,5), # Coco (2017)\n",
    "    (0,72378,4), # \t2012 (2009)\n",
    "    (0,59315,4.5), # Iron Man (2008)\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: ', new_user_ratings_RDD.take(10))\n",
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print (\"New model trained in {} seconds\".format(round(tt,3)) )\n",
    "\n",
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "\n",
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print('TOP 15 recommended movies (with more than 25 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))\n",
    "\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=100).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print('\\nTOP 15 recommended movies (with more than 100 reviews):\\n{}'.format('\\n'.join(map(str, top_movies))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd50372",
   "metadata": {},
   "source": [
    "## Persisting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02c474d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "model_path = os.path.join('..', 'models', 'movie_lens_als')\n",
    "\n",
    "\n",
    "# Delete if exists otherwise save command will fail\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "    \n",
    "# Save and load model\n",
    "new_ratings_model.save(sc, model_path)\n",
    "new_ratings_model = MatrixFactorizationModel.load(sc, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c7d0d",
   "metadata": {},
   "source": [
    "## Persisting the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61e93708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating data saved in parquet format\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "complete_data_with_new_ratings_RDD_df = spark.createDataFrame(complete_data_with_new_ratings_RDD, [\"userId\", \"movieId\", \"rating\"])  # rename columns as needed\n",
    "\n",
    "complete_data_with_new_ratings_RDD_df.write.mode(\"overwrite\").parquet(\"ratings_data.parquet\")\n",
    "\n",
    "print(\"Rating data saved in parquet format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c31de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
